# Voice-Face Association Learning Evaluation

- Reproduce various works based on unified standards ðŸ˜ƒ
- High-speed training and testing âš¡
- Easy to extend ðŸ’­

## Installation

1. Clone or download this repository.

2. Install the required packages:

   ```
   pytorch>=1.8.1
   wandb>=0.12.10
   ```

3. Download the dataset:

   The dataset is based on VoxCeleb and is divided into train/valid/test sets according to "Learnable Pins: Crossmodal Embeddings for Person Identity, 2018, ECCV" (901/100/250).

   Download `dataset.zip` from [Google Drive](https://drive.google.com/file/d/1sVQ7I4_9rwWF18vk4VZFVAx-8Inv-wlT/view?usp=sharing) (2.3GB) and unzip it to the project root directory. The folder structure should be as follows:
   
   ```
   dataset
   â”œâ”€â”€ evals
   â”‚   â”œâ”€â”€ test_matching_10.pkl
   â”‚   â”œâ”€â”€ test_matching_g.pkl
   â”‚   â”œâ”€â”€ test_matching.pkl
   â”‚   â”œâ”€â”€ test_retrieval.pkl
   â”‚   â”œâ”€â”€ test_verification_g.pkl
   â”‚   â”œâ”€â”€ test_verification.pkl
   â”‚   â””â”€â”€ valid_verification.pkl
   â”œâ”€â”€ info
   â”‚   â”œâ”€â”€ name2gender.pkl
   â”‚   â”œâ”€â”€ name2jpgs_wavs.pkl
   â”‚   â”œâ”€â”€ name2movies.pkl
   â”‚   â”œâ”€â”€ name2voice_id.pkl
   â”‚   â”œâ”€â”€ train_valid_test_names.pkl
   â”‚   â””â”€â”€ works
   â”‚       â””â”€â”€ wen_weights.txt
   â”œâ”€â”€ face_input.pkl
   â””â”€â”€ voice_input.pkl
   ```
   
   

## Run a Production

- Learnable Pins: Crossmodal Embeddings for Person Identity, 2018, ECCV

  ```
  python works/1_pins.py
  ```

- Face-Voice Matching using Cross-modal Embeddings, MM, 2018

  ```
  python works/2_FV-CME.py
  ```

- On Learning Associations of Faces and Voices, ACCV, 2018

  ```
  python works/3_LAFV.py
  ```

- Disjoint Mapping Network for Cross-modal Matching of Voices and Faces, ICLR, 2019

  ```
  python works/11_SS_DIM_VFMR_Barlow.py --name=DIMNet
  ```

- Voice-Face Cross-modal Matching and Retrieval - A Benchmark, 2019

  ```
  python works/11_SS_DIM_VFMR_Barlow.py --name=VFMR
  ```

- Seeking the Shape of Sound: An Adaptive Framework for Learning Voice-Face Association, CVPR, 2021

  ```
  python works/5_Wen.py
  ```

- Fusion and Orthogonal Projection for Improved Face-Voice Association, ICASSP, 2022

  ```
  python works/6_FOP.py
  ```

- Unsupervised Voice-Face Representation Learning by Cross-Modal Prototype Contrast, IJCAI, 2022

  ```
  python works/7_CMPC.py
  ```

- Self-Lifting: A Novel Framework for Unsupervised Voice-Face Association Learning, ICMR, 2022

  ```
  python works/9_SL.py
  ```

  for self-lifting 

  ```
  python works/8_CAE.py
  ```

  for the CCAE baseline 

  ```
  python works/11_SS_DIM_VFMR_Barlow.py --name=SL-Barlow
  ```

  for the Barlow Twins baseline 

## Integration with Wandb

*Use [wandb](https://wandb.ai) to view the training process:*

1. Create a `.wb_config.json` file in the project root with the following content:

   ```
   {
     "WB_KEY": "Your wandb auth key"
   }
   ```

2. Add `--dryrun=False` to the training command, for example:

   ```
   python main.py --dryrun=False
   ```

## 